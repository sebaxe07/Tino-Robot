\section{Localization Technologies Review}
This section will provide a comprehensive analysis of available localization technologies for mobile robotics applications, establishing the foundation for the technology selection decisions made in the Tino V2 project. The review will begin with an examination of Visual Odometry (VO) approaches, including both monocular and stereo camera implementations, analyzing their strengths in feature-rich environments and limitations in scenarios with poor lighting or repetitive textures. The discussion will cover ORB-SLAM3 capabilities for RGB-D sensor integration, SVO (Semi-direct Visual Odometry) advantages for fisheye and wide field-of-view cameras, and the computational requirements associated with each approach. Ultra-Wideband (UWB) positioning technology will be evaluated for its centimeter-level accuracy potential, low power consumption characteristics, and infrastructure requirements including anchor placement and calibration procedures. The analysis will address fabric penetration capabilities crucial for Tino's soft structure, Non-Line-of-Sight (NLOS) mitigation strategies, and orientation estimation challenges inherent in UWB systems. Finally, IMU and wheel encoder fusion approaches will be examined, including Extended Kalman Filter (EKF) implementations, drift accumulation issues, and performance limitations on uneven surfaces and with impulse-based movement patterns.

\section{Human Detection Technologies Comparison}
This section will systematically evaluate available human detection and tracking technologies suitable for social robotics applications. RGB-D camera solutions will be analyzed first, examining Intel RealSense and similar depth-sensing cameras for their simultaneous color and depth data capabilities, skeleton tracking potential using OpenPose and MediaPipe frameworks, and integration challenges related to physical mounting and visibility constraints within Tino's fabric structure. Thermal imaging technology will be evaluated for its potential fabric penetration capabilities, performance in low-light conditions, and limitations in providing contextual information beyond heat signatures. The discussion will cover fusion strategies between thermal sensors and other sensing modalities to achieve comprehensive human detection capabilities. LiDAR technology will be assessed for its high-resolution 3D mapping capabilities, though acknowledging its impracticality for Tino's soft structure due to vibration sensitivity and cost considerations. Machine Learning-enhanced 2D camera approaches will be examined, including modern architectures such as YOLOv8 and EfficientNet for real-time detection, monocular depth estimation networks like MiDaS and LeReS, and the computational requirements for real-time processing on embedded platforms.

\section{SLAM Systems Evaluation}
This section will present a detailed technical evaluation of Simultaneous Localization and Mapping (SLAM) systems considered for the Tino V2 implementation. ORB-SLAM3 will be examined first, analyzing its support for monocular, stereo, and RGB-D sensor configurations, robustness in dynamic environments through advanced feature matching, and computational requirements that necessitate GPU optimization for real-time performance. The evaluation will cover map persistence capabilities, loop closure detection mechanisms, and integration challenges encountered during development. SVO (Semi-direct Visual Odometry) will be analyzed for its compatibility with fisheye and catadioptric cameras, reduced computational footprint compared to feature-based methods, and performance limitations in textureless environments. The discussion will include practical implementation challenges and compilation issues encountered on ARM64 architectures. RTABMap (Real-Time Appearance-Based Mapping) will be evaluated as the selected SLAM solution, examining its multi-session mapping capabilities, robust map saving and loading functionality, and superior relocalization performance. The analysis will cover integration with the Oak-D Pro camera through the DepthAI library, ROS2 compatibility, and performance characteristics that made it the optimal choice for the Tino V2 platform.

\section{Technology Selection Rationale}
This section will present the systematic decision-making process that led to the final technology stack selection for Tino V2. The evaluation criteria will be established first, including accuracy requirements for social interaction scenarios, computational efficiency constraints of embedded platforms, integration complexity with existing systems, and reliability requirements for sustained operation. For localization technology selection, the analysis will explain why a hybrid approach combining RTABMap SLAM with UWB positioning was chosen over single-technology solutions. The decision process will cover RTABMap's superior map persistence and relocalization capabilities compared to ORB-SLAM3 and SVO, UWB technology's potential for absolute positioning to address SLAM drift issues, and the complementary nature of visual orientation data from SLAM with precise positioning from UWB systems. For human detection technology selection, the rationale for choosing YOLOv11 with TensorRT optimization will be presented, including real-time performance capabilities, accuracy in detecting multiple humans simultaneously, and successful integration with stereo depth data for 3D positioning. The section will address why this approach was preferred over thermal imaging or pure RGB-D solutions, considering Tino's specific operational requirements and physical constraints.

\section{Hybrid Approach Justification}
This section will provide detailed justification for the hybrid localization approach that combines multiple sensing modalities to achieve superior performance compared to individual technologies. The limitations of SLAM-only approaches will be discussed first, including drift accumulation over extended operation periods, relocalization failures in feature-poor environments, and map corruption issues that can compromise long-term operation. Specific examples from the development process will illustrate scenarios where RTABMap exhibited positioning drift up to 1.2 meters, necessitating manual intervention or robot rotation to achieve relocalization. The complementary capabilities of UWB positioning will be explained, demonstrating how centimeter-level absolute positioning addresses SLAM drift issues while maintaining the rich environmental understanding provided by visual SLAM systems. The sensor fusion strategy will be detailed, explaining how RTABMap provides reliable orientation information and environmental mapping while UWB delivers precise global positioning, creating a robust localization system that leverages the strengths of both technologies. Performance comparisons will be presented showing the improved accuracy and reliability achieved through the hybrid approach compared to individual sensor modalities.

\section{Selected Technology Stack for Tino V2}
This section will present the final integrated technology stack selected for the Tino V2 platform, providing a comprehensive overview of how individual components work together to achieve the project objectives. The hardware platform selection will be detailed first, explaining the migration from Raspberry Pi to NVIDIA Orin Nano and the performance benefits this transition enables for real-time SLAM processing, computer vision algorithms, and multi-modal sensor fusion. The Oak-D Pro camera selection will be justified for its stereo depth capabilities, DepthAI library integration, and compatibility with RTABMap SLAM implementation. The localization system architecture will be presented, describing the integration of RTABMap SLAM for visual odometry and mapping with UWB positioning for absolute coordinate reference, including the sensor fusion algorithms that combine these data streams. The human detection pipeline will be detailed, covering YOLOv11 implementation with TensorRT optimization, stereo depth integration for 3D human positioning, and real-time skeleton tracking with 17 key body joints. The software architecture selection will explain the migration to ROS2 for improved modularity, the node-based system design that enables independent development and testing of subsystems, and the communication protocols that facilitate integration with VR systems and external applications.
