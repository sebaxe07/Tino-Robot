\section{RTABMap Integration with Oak-D Pro Camera}
This section will detail the comprehensive implementation of RTABMap (Real-Time Appearance-Based Mapping) SLAM system with the Oak-D Pro camera, establishing the foundation for Tino V2's localization capabilities. The Oak-D Pro camera integration will be explained first, covering the DepthAI library implementation that provides seamless access to stereo depth data, the ROS2 wrapper configuration that publishes synchronized color and depth image streams, and the camera calibration procedures that ensure accurate depth estimation and feature detection. The RTABMap configuration process will be detailed, including the parameter optimization for indoor environments, memory management settings that enable long-term operation without performance degradation, and the feature detection and matching algorithms that provide robust visual odometry in dynamic social interaction scenarios. The stereo vision implementation will be examined, covering how the Oak-D Pro's dual camera system provides depth information for feature triangulation, the baseline calibration that ensures accurate 3D point cloud generation, and the integration with RTABMap's visual-inertial odometry algorithms. The real-time performance optimization will be discussed, including the computational load balancing between feature extraction and map building processes, the memory allocation strategies that prevent system crashes during extended mapping sessions, and the parameter tuning that achieves optimal performance on the Orin Nano platform.

\section{SLAM Mapping and Localization Modes}
This section will explain the dual operational modes implemented in the Tino V2 system, enabling both map creation and autonomous navigation capabilities. The mapping mode implementation will be detailed first, covering the launch file configuration (rtab\_mapping.launch.py) that initializes all necessary nodes for map creation, the real-time visualization capabilities that allow monitoring of map building progress, and the landmark placement strategies that improve map quality and relocalization reliability. The map building process will be examined, including the loop closure detection mechanisms that ensure map consistency, the keyframe selection algorithms that optimize memory usage while maintaining map quality, and the feature database management that enables efficient storage and retrieval of visual landmarks. The localization mode implementation will be explained, covering the launch file configuration (rtab\_localization.launch.py) that loads existing maps and initializes positioning systems, the relocalization algorithms that enable the robot to determine its position within a previously created map, and the continuous tracking mechanisms that maintain accurate positioning during navigation. The mode switching procedures will be detailed, including the map saving and loading protocols that ensure data persistence, the system state management that enables seamless transitions between mapping and localization modes, and the parameter configuration changes required for optimal performance in each operational mode.

\section{Initial SLAM-Only System Limitations and Drift Issues}
This section will present a comprehensive analysis of the limitations discovered during initial testing of the SLAM-only localization approach, providing the technical justification for implementing the hybrid sensor fusion system. The drift accumulation problems will be documented first, including specific measurement data showing position errors of up to 1.2 meters during extended operation, the systematic analysis of error sources including visual odometry drift and map inconsistencies, and the environmental factors that contribute to localization degradation such as lighting changes and repetitive textures. The relocalization challenges will be examined, covering scenarios where RTABMap failed to correctly determine robot position within existing maps, the feature-poor environments that caused tracking failures, and the manual intervention requirements (robot rotation) needed to achieve successful relocalization. The performance testing methodology will be detailed, including the four-position testing protocol implemented to quantify localization accuracy, the repeated measurement procedures that revealed consistency issues, and the statistical analysis of position errors that demonstrated the need for absolute positioning reference. The specific failure modes will be analyzed, covering map corruption events that required complete map reconstruction, tracking loss scenarios that occurred near walls or in areas with insufficient visual features, and the computational resource limitations that affected real-time performance during intensive mapping operations.

\section{UWB Positioning System Implementation}
This section will detail the Ultra-Wideband (UWB) positioning system integration that provides absolute positioning reference to complement the visual SLAM system. The UWB hardware implementation will be explained first, covering the anchor placement strategy that ensures optimal coverage of the operating environment, the calibration procedures that establish accurate position references, and the tag integration with the Tino robot platform that minimizes interference with other systems. The positioning algorithm implementation will be detailed, including the multilateration techniques that calculate 3D position from multiple anchor measurements, the Non-Line-of-Sight (NLOS) mitigation strategies that improve accuracy in complex indoor environments, and the filtering algorithms that reduce measurement noise and provide stable position estimates. The coordinate system alignment will be examined, covering the transformation procedures that align UWB coordinates with the SLAM coordinate frame, the map offset implementation that enables rotational correction of SLAM maps, and the calibration protocols that ensure consistent positioning across different operational sessions. The real-time performance characteristics will be analyzed, including the update rates achieved by the UWB system, the latency measurements that demonstrate suitability for real-time control applications, and the accuracy evaluation that shows centimeter-level positioning precision under optimal conditions.

\section{Sensor Fusion Between RTABMap Orientation and UWB Positioning}
This section will present the sophisticated sensor fusion approach that combines the complementary strengths of visual SLAM and UWB positioning to achieve superior localization performance. The fusion algorithm design will be explained first, covering the Extended Kalman Filter (EKF) implementation that optimally combines position and orientation data from multiple sources, the state estimation procedures that maintain accurate robot pose estimates, and the uncertainty quantification methods that provide confidence measures for navigation decisions. The data synchronization implementation will be detailed, including the timestamp alignment procedures that ensure temporal consistency between sensor measurements, the interpolation algorithms that handle different update rates from SLAM and UWB systems, and the buffering mechanisms that maintain data integrity during temporary sensor outages. The orientation and position separation strategy will be examined, covering how RTABMap provides reliable orientation information while UWB delivers absolute position data, the coordinate transformation procedures that maintain consistency between different sensor coordinate frames, and the validation algorithms that detect and reject outlier measurements. The adaptive fusion parameters will be discussed, including the dynamic weighting strategies that adjust fusion coefficients based on sensor reliability, the fault detection mechanisms that identify sensor malfunctions or degraded performance, and the graceful degradation procedures that maintain operation when individual sensors fail.

\section{Final Hybrid Localization System Performance}
This section will present comprehensive performance evaluation of the final hybrid localization system, demonstrating the improvements achieved through sensor fusion compared to individual sensing modalities. The accuracy evaluation will be detailed first, including quantitative measurements comparing SLAM-only, UWB-only, and hybrid system performance, statistical analysis of position errors showing significant improvement in the fused system, and repeatability testing that demonstrates consistent performance across multiple operational sessions. The specific performance data will be presented, covering the four-position testing results that show centimeter-level accuracy with the hybrid system, the position consistency measurements that demonstrate reduced drift compared to SLAM-only operation, and the orientation accuracy evaluation that validates the continued use of visual odometry for heading estimation. The operational reliability improvements will be examined, including the reduced need for manual relocalization procedures, the improved performance in challenging environments with poor visual features, and the enhanced system stability during extended autonomous operation. The computational performance analysis will be discussed, covering the processing load distribution between SLAM and UWB systems, the real-time performance characteristics that meet the requirements for responsive robot control, and the memory usage optimization that enables continuous operation without system degradation. Finally, the system robustness evaluation will be presented, including fault tolerance testing that demonstrates graceful degradation when individual sensors fail, environmental adaptability testing that shows consistent performance across different lighting and structural conditions, and long-term stability evaluation that validates the system's suitability for extended autonomous operation in social robotics applications.
