\section{VR System Architecture and Unity Communication}
This section will detail the comprehensive VR integration system that enables remote control and monitoring of Tino through Unity-based VR environments. The VR interface architecture will be explained first, covering the ROS2 \texttt{vr\_interface\_node} that serves as the central communication bridge between the robot's ROS2 system and external Unity applications, and the UDP communication protocol that provides real-time bidirectional data exchange for low-latency VR interaction. The Unity integration capabilities will be detailed, including the message structures for sending robot control commands from VR to ROS2 topics, the data reception system that provides robot pose, human detection, and audio information to Unity for visualization and interaction, and the networking configuration that enables flexible deployment across different network environments. The communication monitoring system will be examined, covering the configurable send rates for pose and skeleton data transmission, the health monitoring that tracks communication status and detects connection failures, and the message ordering system that ensures reliable data delivery and duplicate detection. The VR data recording functionality will be discussed, including the comprehensive recording system that captures all VR-relevant data streams for offline analysis.

\section{Atomic Movement System Design and 4-State Control Architecture}
This section will present the revolutionary atomic movement system designed specifically for natural VR interaction, replacing the previous continuous control scheme with discrete, completion-guaranteed movements. The 4-state control framework will be explained first, covering the unified state architecture applied to both leg and base controllers where state 0 represents idle/resting position, state 1 implements expressive ``little push'' movements for attention-getting behaviors, state 2 provides timing synchronization cycles, and state 3 executes atomic movements that must complete before new commands can be processed. The leg controller implementation will be detailed, including the state 1 optimized 3-phase movement (50\% forward extension, 5\% pause, 45\% return), the state 2 forward extension to maximum reach with position locking mechanisms, and the state 3 return-to-neutral movement with button-press completion detection. The base controller design will be examined, covering the state 1 rapid forward-backward sequence for expressive pointing behaviors, the state 2 timing cycle that provides 1.5-second synchronization delay, and the state 3 atomic movements including forward translation and left/right rotation operations, each with 1.7-second execution duration. The synchronization architecture will be discussed, including the sophisticated locking system that prevents base state 3 execution until leg state 2 completion, and the pending command system that stores VR commands during ongoing operations and automatically executes them upon completion.

\section{Pulse-Based Command System for VR Integration}
This section will detail the pulse-based command architecture that ensures perfect correspondence between VR user actions and physical robot movements. The pulse generation system will be explained first, covering the replacement of continuous signal transmission with discrete 3-cycle command pulses that automatically return to idle state, ensuring each VR interaction triggers exactly one complete robot movement cycle. The gamepad integration modifications will be detailed, including the removal of analog joystick control in favor of discrete button-based state commands, and the implementation of pulse timing that provides consistent command duration regardless of user input duration. The VR command processing will be examined, covering the UDP packet structure that transmits head control data (pitch, pan, tilt), base movement commands (state and angular direction), and audio parameters (volume and orientation), all synchronized with message ordering for reliable delivery. The atomic guarantee system will be discussed, including the movement completion assurance that prevents partial operations, the state machine locks that maintain movement integrity, and the natural interaction flow that ensures VR users always observe complete robot actions rather than interrupted movements. The timing optimization will be addressed, covering the precise 1.5-second state 2 timing cycle, the 1.7-second state 3 movement duration, and the synchronization mechanisms that coordinate multi-component movements for realistic dragging simulation.

\section{Unity-ROS2 Communication Protocol and Message Structures}
This section will present the comprehensive communication protocol designed for robust Unity-VR to ROS2 integration with optimal performance and reliability. The UDP communication architecture will be explained first, covering the multi-port configuration with port 5005 for incoming VR commands, port 5006 for outgoing robot pose data, and port 5007 for human skeleton transmission, enabling parallel data streams without interference. The incoming message format will be detailed, including the 32-byte VR command packets containing 3 floats for head control (pitch, pan, tilt), 2 integers for base commands (state 0--3, angular direction $-1/0/1$), 2 values for audio control (volume and orientation), and 1 integer for message ordering to detect lost or duplicate packets. The outgoing data structures will be examined, covering the 24-byte robot pose packets with position and orientation data fused from UWB and RTAB-Map systems, and the 208-byte skeleton packets containing exactly 17 COCO-format joints with consistent 3D coordinates for missing or occluded body parts. The configurable transmission rates will be discussed, including independent control of pose data frequency (default 10Hz), skeleton data frequency (default 10Hz), and expected incoming command rate (default 25Hz) to optimize performance for different network conditions and VR application requirements. The monitoring and debugging capabilities will be addressed, covering the comprehensive logging system that tracks communication health, the rate validation that ensures expected data flow, and the error detection mechanisms that identify connection problems and provide detailed diagnostic information for system maintenance.

\section{Bidirectional Audio Communication and Spatial Processing}
This section will detail the advanced audio communication system that enables natural voice interaction between VR users and the physical robot environment. The audio data flow architecture will be explained first, covering the microphone input processing that captures robot-side audio and transmits it to VR systems through ROS2 topics, the VR audio reception that provides spatial audio information with volume and orientation parameters for immersive sound positioning, and the bidirectional communication that enables real-time voice interaction between VR users and people in the robot's physical environment. The audio processing implementation will be detailed, including the 16-bit PCM audio sample handling through Int16MultiArray message structures, the real-time audio streaming that maintains low latency for natural conversation flow, and the volume and orientation control system that allows VR applications to adjust audio characteristics based on virtual positioning and interaction context. The spatial audio integration will be examined, covering the orientation parameter system that provides directional audio information in degrees, the volume control mechanisms that enable distance-based audio attenuation simulation, and the Unity integration capabilities that support immersive audio experiences in VR environments. The practical applications will be discussed, including the human-robot interaction enhancement through voice communication, the remote presence capabilities that allow VR users to participate in physical environment conversations, and the research data collection features that record audio interactions for analysis of human-robot communication patterns and social interaction behaviors.

\section{VR Data Recording and Research Integration}
This section will present the comprehensive VR data recording system designed for research applications and offline VR development. The data recording architecture will be explained first, covering the \texttt{vr\_data\_recorder\_node} that subscribes to all VR-relevant topics including robot pose, human detection, skeleton tracking, and audio streams, the SQLite database storage system that efficiently captures timestamped message data for comprehensive interaction analysis, and the recording control services that enable start\slash{}stop functionality for targeted data collection sessions. The Unity integration tools will be detailed, including the data extraction utilities that convert ROS2 message data into Unity-compatible JSON formats, the offline playback capabilities that enable VR development and testing without requiring live robot connection, and the message structure preservation that maintains full fidelity of robot sensor data for accurate VR simulation. The research applications will be examined, covering the human-robot interaction analysis enabled by synchronized recording of human pose detection, robot movements, and audio communication, the VR user behavior studies that analyze interaction patterns and command sequences, and the system performance evaluation that tracks communication rates, latency, and reliability metrics across different operational scenarios. The development workflow benefits will be discussed, including the VR application testing capabilities that use recorded data for consistent development environments, the debugging tools that enable analysis of communication problems and timing issues, and the educational applications that provide realistic robot interaction data for VR training and demonstration purposes. Finally, the extensibility features will be addressed, covering the modular recording system that can be configured for specific research requirements, the data format compatibility that supports integration with external analysis tools, and the scalability considerations that enable recording of extended interaction sessions for longitudinal studies.
