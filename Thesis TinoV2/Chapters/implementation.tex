\section{Hardware Platform Migration and Integration}
This section will detail the complete hardware migration from the legacy Raspberry Pi system to the modern NVIDIA Orin Nano platform and the integration of new sensing technologies. The computing platform upgrade will be presented first, covering the migration process from Raspberry Pi 4 to NVIDIA Orin Nano including performance benchmarking that demonstrated substantial improvements in processing capability, the power system redesign using DC-DC converters to provide stable 19V power for the Orin Nano from 12V battery systems, and the cooling and thermal management solutions implemented to ensure reliable operation during intensive computational tasks. The camera system integration will be detailed, covering the replacement of the basic Pi camera with the Oak-D Pro depth camera system, the mechanical mounting solutions developed including the tripod-based camera support system and protective housing that shields the camera while maintaining visibility, and the camera calibration procedures required for accurate depth estimation and SLAM performance. The UWB positioning system implementation will be examined, covering the anchor placement strategy developed for the laboratory environment, the coordinate system calibration procedures that align UWB global coordinates with the robot's local reference frame, and the integration of UWB receivers with the Orin Nano through USB interfaces and custom ROS2 drivers. The mechanical system upgrades will be addressed, covering the complete redesign of the base locomotion system from omnidirectional triksta wheels to differential drive configuration, the motor and driver upgrades that provide increased power and reliability for the heavier Orin Nano system, and the Stewart platform head improvements including new arm designs with heim joints that eliminate flex and improve reliability.

\section{ROS2 Software Architecture Implementation}
This section will present the complete implementation of the ROS2-based software architecture that replaced the legacy monolithic Python scripts with a modular, maintainable system. The node architecture design will be established first, covering the development of specialized ROS2 nodes including gamepad\_node.py for Xbox controller input processing, hardware\_interface\_node.py for Arduino communication management, robot\_controller\_node.py for central coordination and behavior management, and vr\_interface\_node.py for Unity integration and data exchange. The communication framework implementation will be detailed, covering the ROS2 topic structure that enables real-time data sharing between nodes, the service interfaces used for system configuration and control commands, the parameter management system that allows runtime configuration of system behavior, and the launch file organization that enables easy switching between mapping and localization operational modes. The Arduino integration will be examined, covering the serial communication protocols developed for reliable data exchange with head, base, and leg control systems, the device symlink configuration that ensures consistent device addressing across system restarts, and the command processing logic that translates high-level movement commands into appropriate motor control signals. The data recording and analysis infrastructure will be presented, covering the implementation of comprehensive logging systems that capture all sensor data, robot states, and user interactions for later analysis, the data extraction tools developed for processing recorded sessions, and the visualization systems that enable real-time monitoring of system performance and debugging of operational issues.

\section{SLAM and Sensor Fusion Implementation}
This section will detail the implementation of the RTABMap SLAM system and its integration with UWB positioning for robust indoor localization. The RTABMap configuration and optimization will be presented first, covering the parameter tuning process that optimized performance for the Oak-D Pro camera system, the memory management configuration that enables long-term mapping without excessive resource consumption, and the loop closure detection settings that ensure reliable map consistency during extended operation. The UWB integration implementation will be detailed, covering the development of custom ROS2 nodes for UWB data processing and coordinate transformation, the sensor fusion logic that combines UWB position data with RTABMap orientation information, and the coordinate system alignment procedures that ensure consistent mapping between UWB global coordinates and robot local coordinates. The mapping and localization modes will be examined, covering the implementation of distinct operational modes for initial map creation and subsequent localization within existing maps, the map saving and loading procedures that enable persistent environment representations, and the automatic relocalization capabilities that allow the robot to recover its position after temporary tracking loss. The performance optimization will be addressed, covering the computational optimization that enables real-time SLAM processing on the Orin Nano platform, the memory management strategies that prevent performance degradation during extended mapping sessions, and the error handling procedures that maintain system stability when sensor data is temporarily unavailable or degraded.

\section{Human Detection and Pose Estimation Implementation}
This section will present the implementation of real-time human detection and pose estimation using YOLOv11 with TensorRT optimization. The YOLOv11 model preparation and optimization will be detailed first, covering the conversion process from PyTorch models to TensorRT optimized engines for the Orin Nano platform, the model quantization and optimization strategies that balance detection accuracy with inference speed, and the integration with the Oak-D Pro camera system that enables simultaneous RGB and depth data processing for 3D pose estimation. The real-time processing pipeline will be examined, covering the image preprocessing and postprocessing steps that prepare camera data for inference and extract meaningful pose information, the coordinate transformation calculations that convert 2D detection results to 3D world coordinates using depth information, and the tracking algorithms that maintain consistent person identification across multiple frames. The pose estimation implementation will be detailed, covering the 17-keypoint skeleton detection that provides comprehensive human pose information, the depth integration that enables accurate 3D position calculation for each detected person, and the filtering and smoothing algorithms that reduce noise and provide stable pose tracking despite occasional detection errors. The integration with robot systems will be addressed, covering the ROS2 message structures used to publish human detection and pose data for use by other system components, the coordinate system transformations that align human pose data with robot and world coordinate frames, and the performance monitoring systems that track detection accuracy and computational load to ensure real-time operation requirements are maintained.

\section{VR Integration and Atomic Movement System Implementation}
This section will detail the implementation of the complete VR integration system including Unity-based user interfaces and atomic movement control architecture. The Unity VR application development will be presented first, covering the creation of immersive VR environments that provide intuitive robot control interfaces, the implementation of bidirectional communication systems that enable real-time data exchange between Unity and ROS2, and the user interface design that makes robot control accessible to users without technical expertise. The ROS-TCP-Endpoint integration will be examined, covering the implementation of reliable communication bridges between Unity and the ROS2 ecosystem, the message serialization and deserialization procedures that handle complex data structures, and the error handling and reconnection logic that maintains communication stability despite network interruptions. The atomic movement system implementation will be detailed, covering the four-state control architecture implemented in both leg and base controllers, the synchronization mechanisms that ensure coordinated movement between robot subsystems, and the command queuing and locking systems that prevent conflicting movement commands. The audio system integration will be addressed, covering the implementation of bidirectional audio communication that enables natural conversation between VR users and people near the robot, the audio processing pipelines that handle microphone input and speaker output, and the integration with the VR system that provides seamless audio transmission. The data recording and analysis implementation will be presented, covering the comprehensive logging systems that capture all VR interactions, robot responses, and sensor data for detailed analysis of human-robot interaction patterns, the data extraction and visualization tools that enable researchers to analyze user behavior and system performance, and the real-time monitoring systems that provide immediate feedback about system operation and performance metrics during VR sessions.

\section{System Integration and Testing Infrastructure}
This section will present the implementation of comprehensive system integration procedures and testing infrastructure that ensure reliable operation of all system components. The integration testing methodology will be established, covering the systematic approach used to validate individual subsystem functionality before full system integration, the interface testing procedures that verify reliable communication between ROS2 nodes, and the end-to-end testing protocols that validate complete system operation from VR input to robot response. The calibration and configuration management will be detailed, covering the sensor calibration procedures required for accurate camera, UWB, and coordinate system alignment, the parameter management systems that store and maintain optimal configuration settings for different operational scenarios, and the automated configuration validation tools that detect and report configuration errors or drift. The debugging and monitoring infrastructure will be examined, covering the comprehensive logging systems that capture detailed system state information for troubleshooting and optimization, the real-time monitoring displays that provide immediate feedback about system performance and health, and the automated error detection and reporting systems that identify and classify system issues to support rapid problem resolution. The deployment and maintenance procedures will be addressed, covering the automated setup scripts that streamline system installation and configuration, the backup and recovery procedures that protect against data loss and enable rapid system restoration, and the update and maintenance protocols that enable safe system modification and capability enhancement without disrupting ongoing research activities.
